# TODO

## Generate code coverage from an event log file

Piggly is split up into separate phases (recompile procs, install them, run
while recording events, uninstall the procs, generate report). If the run +
record step was split in two, piggly could be fed a text file generated by
tests run in any language.

* dump procs to cache
* recompile procs
* install recompiled procs
* clear coverage
* execute tests
* reinstall original procs
* update coverage
* generate report index
* generate reports

## Rudimentary profiling

There is no easy way to profile PL/pgSQL besides adding `raise info '%', now`
manually. Piggly's instrumentation support procs could easily be extended to
print timestamps on each event. It's not clear how to present this information
in the report without it becoming cluttered.

## Coverage pragmas

Some loops and branches cannot be fully covered in practice. It might be useful
to extend piggly to recognize pragmas like `-- piggly: no coverage`, so certain
nodes wouldn't be tagged. However, it may ambiguous which node was intended to
be annotated in a nest of nodes... and should the pragma apply to the node's
descendants?

## Small things
* Check support for numbered (unnamed) paramaters in method signature like $1, $2, etc.
* Summary row in the report index
* Configurable filter to select which procs are dumped/instrumented/reported
* Remove linebreaks from Compiler::Trace, so error messages line numbers match
  the report and the original uninstrumented source
* Print the percent change in coverage after "Reporting coverage for ..."
* Intermittant dumper bug: removed procs, ran tests. restored procs and made edits
  to other procs. Running didn't "cache source" for restored procs, then cacheable.rb:143
  `read' failed "no such file or directory". Running a third time recovers from
  "failed to load source for ..." and then "caching source for ..."
